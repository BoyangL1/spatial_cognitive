{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings \n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_be = gpd.read_file('./data_pe/grids_with_BE.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedColumns = ['fnid','pre_home_distance', 'post_home_distance', 'LU_Business',\n",
    "                        'LU_City_Road', 'LU_Consumption', 'LU_Culture', 'LU_Industry',\n",
    "                        'LU_Medical', 'LU_Park_&_Scenery', 'LU_Public', 'LU_Residence',\n",
    "                        'LU_Science_&_Education', 'LU_Special', 'LU_Transportation', 'LU_Wild']\n",
    "be_data = grid_be[selectedColumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_coords = grid_be.geometry.centroid\n",
    "be_data['x'] = grid_coords.x\n",
    "be_data['y'] = grid_coords.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_be_data = be_data.drop(columns=['pre_home_distance']).rename(columns={'post_home_distance': 'home_distance'})\n",
    "before_be_data = be_data.drop(columns=['post_home_distance']).rename(columns={'pre_home_distance': 'home_distance'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SCBIRL_Global_PE.SCBIRLTransformer as SIRLT\n",
    "import SCBIRL_Global_PE.utils as SIRLU\n",
    "import SCBIRL_Global_PE.migrationProcess as SIRLP\n",
    "\n",
    "data_dir = './data/'\n",
    "before_migration_path = data_dir + 'before_migrt.json'\n",
    "full_trajectory_path = data_dir + 'all_traj.json'\n",
    "\n",
    "inputs, targets_action, pe_code, action_dim, state_dim = SIRLU.loadTrajChain(before_migration_path, full_trajectory_path)\n",
    "model = SIRLT.avril(inputs, targets_action, pe_code, state_dim, action_dim, state_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getComputeFunction(model, attribute_type):\n",
    "    \"\"\"Return the appropriate function to compute either 'value' or 'reward'.\"\"\"\n",
    "    if attribute_type == 'value':\n",
    "        return lambda state,grid_code: np.max(model.QValue(state,grid_code))\n",
    "    elif attribute_type == 'reward':\n",
    "        return lambda state,grid_code: model.reward(state,grid_code)[0][0][0]\n",
    "    else:\n",
    "        raise ValueError(\"attribute_type should be either 'value' or 'reward'.\")\n",
    "    \n",
    "Q = np.load('./data_pe/Q_matrix.npy')\n",
    "with open('./data_pe/random_angle_list.pkl', 'rb') as file:\n",
    "    angle_list = pickle.load(file)\n",
    "def globalPE(coords,dimension):\n",
    "    x,y = coords\n",
    "    for k in range(1,dimension+1):\n",
    "        theta = 2 * np.pi / 3  \n",
    "        angle = angle_list[k-1]\n",
    "        R = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\n",
    "        scale_factor = (200**(k/dimension))\n",
    "        omega_n0 = np.array([np.cos(angle), np.sin(angle)]) * scale_factor\n",
    "        omega_n1 = R.dot(omega_n0)\n",
    "        omega_n2 = R.dot(omega_n1)\n",
    "\n",
    "        coords = np.vstack((x, y))\n",
    "        eiw0x = np.exp(1j * np.dot(omega_n0,coords))\n",
    "        eiw1x = np.exp(1j * np.dot(omega_n1,coords))\n",
    "        eiw2x = np.exp(1j * np.dot(omega_n2,coords))\n",
    "\n",
    "        g_n = Q.dot(np.array([eiw0x, eiw1x, eiw2x]))\n",
    "        if k == 1:\n",
    "            g = g_n\n",
    "        else:\n",
    "            g = np.concatenate((g, g_n), axis=0)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate reward for all grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load params from ./model/params_transformer_pe.pickle!\n"
     ]
    }
   ],
   "source": [
    "model.loadParams('./model/params_transformer_pe.pickle')\n",
    "rewardFunction = getComputeFunction(model, 'reward')\n",
    "def calculate_reward(row):\n",
    "    coords = (row.x, row.y)\n",
    "    state = row[1:15]\n",
    "    pe_code = globalPE(coords,len(state)).flatten()\n",
    "    pe_code = np.expand_dims(np.expand_dims(np.expand_dims(pe_code, axis=0), axis=0), axis = 0)\n",
    "    state = np.expand_dims(np.expand_dims(np.expand_dims(state, axis=0), axis=0), axis = 0)\n",
    "    return float(rewardFunction(state, pe_code))\n",
    "before_be_data['reward'] = before_be_data.apply(calculate_reward, axis=1)\n",
    "before_be_data.to_csv('./data_pe/all_grid_before.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load params from ./data_pe/after_migrt/model_random/20190707.pickle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/13 [07:53<1:34:36, 473.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load params from ./data_pe/after_migrt/model_random/20190715.pickle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 2/13 [15:46<1:26:47, 473.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load params from ./data_pe/after_migrt/model_random/20190801.pickle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 3/13 [23:41<1:19:01, 474.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load params from ./data_pe/after_migrt/model_random/20190815.pickle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 4/13 [31:38<1:11:16, 475.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load params from ./data_pe/after_migrt/model_random/20190901.pickle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 5/13 [39:32<1:03:17, 474.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load params from ./data_pe/after_migrt/model_random/20190915.pickle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 6/13 [47:27<55:23, 474.80s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load params from ./data_pe/after_migrt/model_random/20191001.pickle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 7/13 [55:22<47:30, 475.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load params from ./data_pe/after_migrt/model_random/20191015.pickle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 8/13 [1:03:20<39:39, 475.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load params from ./data_pe/after_migrt/model_random/20191101.pickle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 9/13 [1:11:15<31:42, 475.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load params from ./data_pe/after_migrt/model_random/20191115.pickle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 10/13 [1:19:09<23:45, 475.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load params from ./data_pe/after_migrt/model_random/20191201.pickle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 11/13 [1:27:09<15:53, 476.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load params from ./data_pe/after_migrt/model_random/20191216.pickle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 12/13 [1:35:02<07:55, 475.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load params from ./data_pe/after_migrt/model_random/20191231.pickle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [1:42:57<00:00, 475.19s/it]\n"
     ]
    }
   ],
   "source": [
    "model_dir = './data_pe/after_migrt/model_random/'\n",
    "save_dir = './data_pe/after_migrt/all_grid/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "pickle_files = [file for file in os.listdir(model_dir) if file.endswith('.pickle')]\n",
    "for pickle_file in tqdm(pickle_files):\n",
    "    temp_after_be_data = after_be_data.copy()\n",
    "    file_path = os.path.join(model_dir,pickle_file)\n",
    " \n",
    "    model.loadParams(file_path)\n",
    "    rewardFunction = lambda state,grid_code: model.reward(state,grid_code)[0][0][0]\n",
    "    rewards = []\n",
    "\n",
    "    for index, row in temp_after_be_data.iterrows():\n",
    "        coords = (row.x, row.y)\n",
    "        state = row[1:15] \n",
    "        pe_code = globalPE(coords, len(state)).flatten()\n",
    "        pe_code = np.expand_dims(np.expand_dims(np.expand_dims(pe_code, axis=0), axis=0), axis=0)\n",
    "        state = np.expand_dims(np.expand_dims(np.expand_dims(state, axis=0), axis=0), axis=0)\n",
    "        reward = float(rewardFunction(state, pe_code))\n",
    "        rewards.append(reward)\n",
    "    temp_after_be_data['reward'] = rewards\n",
    "    \n",
    "    # Save the updated DataFrame to a CSV file in the save_dir\n",
    "    csv_file_name = pickle_file.replace('.pickle', '.csv')\n",
    "    csv_file_path = os.path.join(save_dir, csv_file_name)\n",
    "    temp_after_be_data.to_csv(csv_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
