{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings \n",
    "from tqdm import tqdm\n",
    "import os\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_be = gpd.read_file('./data_pe/grids_with_BE.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedColumns = ['fnid','pre_home_distance', 'post_home_distance', 'LU_Business',\n",
    "                        'LU_City_Road', 'LU_Consumption', 'LU_Culture', 'LU_Industry',\n",
    "                        'LU_Medical', 'LU_Park_&_Scenery', 'LU_Public', 'LU_Residence',\n",
    "                        'LU_Science_&_Education', 'LU_Special', 'LU_Transportation', 'LU_Wild']\n",
    "be_data = grid_be[selectedColumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_coords = grid_be.geometry.centroid\n",
    "be_data['x'] = grid_coords.x\n",
    "be_data['y'] = grid_coords.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_be_data = be_data.drop(columns=['pre_home_distance']).rename(columns={'post_home_distance': 'home_distance'})\n",
    "before_be_data = be_data.drop(columns=['post_home_distance']).rename(columns={'pre_home_distance': 'home_distance'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SCBIRL_Global_PE.SCBIRLTransformer as SIRLT\n",
    "import SCBIRL_Global_PE.utils as SIRLU\n",
    "import SCBIRL_Global_PE.migrationProcess as SIRLP\n",
    "\n",
    "data_dir = './data/'\n",
    "before_migration_path = data_dir + 'before_migrt.json'\n",
    "full_trajectory_path = data_dir + 'all_traj.json'\n",
    "\n",
    "inputs, targets_action, pe_code, action_dim, state_dim = SIRLU.loadTrajChain(before_migration_path, full_trajectory_path)\n",
    "model = SIRLT.avril(inputs, targets_action, pe_code, state_dim, action_dim, state_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getComputeFunction(model, attribute_type):\n",
    "    \"\"\"Return the appropriate function to compute either 'value' or 'reward'.\"\"\"\n",
    "    if attribute_type == 'value':\n",
    "        return lambda state,grid_code: np.max(model.QValue(state,grid_code))\n",
    "    elif attribute_type == 'reward':\n",
    "        return lambda state,grid_code: model.reward(state,grid_code)[0][0][0]\n",
    "    else:\n",
    "        raise ValueError(\"attribute_type should be either 'value' or 'reward'.\")\n",
    "    \n",
    "def globalPE(coords,dimension):\n",
    "    x = coords[0]\n",
    "    y = coords[1]\n",
    "    pe = [0]*dimension\n",
    "    for k in range(1,dimension+1):\n",
    "        w = (100**(k/dimension))\n",
    "        pe[k-1] = np.sin(x*w) + np.sin(y*w)\n",
    "    return np.array(pe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate reward for all grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.loadParams('./model/params_transformer_pe.pickle')\n",
    "rewardFunction = getComputeFunction(model, 'reward')\n",
    "def calculate_reward(row):\n",
    "    coords = (row.x, row.y)\n",
    "    state = row[1:15]\n",
    "    pe_code = globalPE(coords, len(state))\n",
    "    pe_code = np.expand_dims(np.expand_dims(np.expand_dims(pe_code, axis=0), axis=0), axis=0)\n",
    "    state = np.expand_dims(np.expand_dims(np.expand_dims(state, axis=0), axis=0), axis=0)\n",
    "    return float(rewardFunction(state, pe_code))\n",
    "before_be_data['reward'] = before_be_data.apply(calculate_reward, axis=1)\n",
    "before_be_data.to_csv('./data_pe/all_grid_before.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load params from ./data_pe/after_migrt/model_random/20190901.pickle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [06:33<52:30, 393.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load params from ./data_pe/after_migrt/model_random/20190915.pickle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [13:17<46:39, 399.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load params from ./data_pe/after_migrt/model_random/20191001.pickle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [19:50<39:40, 396.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load params from ./data_pe/after_migrt/model_random/20191015.pickle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [26:47<33:43, 404.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load params from ./data_pe/after_migrt/model_random/20191101.pickle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [33:45<27:17, 409.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load params from ./data_pe/after_migrt/model_random/20191115.pickle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [40:28<20:22, 407.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load params from ./data_pe/after_migrt/model_random/20191201.pickle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [47:11<13:31, 405.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load params from ./data_pe/after_migrt/model_random/20191214.pickle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [53:57<06:45, 405.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load params from ./data_pe/after_migrt/model_random/20191231.pickle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [1:00:24<00:00, 402.73s/it]\n"
     ]
    }
   ],
   "source": [
    "model_dir = './data_pe/after_migrt/model_random/'\n",
    "save_dir = './data_pe/after_migrt/all_grid/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "pickle_files = [file for file in os.listdir(model_dir) if file.endswith('.pickle')]\n",
    "for pickle_file in tqdm(pickle_files):\n",
    "    temp_after_be_data = after_be_data.copy()\n",
    "    file_path = os.path.join(model_dir,pickle_file)\n",
    " \n",
    "    model.loadParams(file_path)\n",
    "    rewardFunction = lambda state,grid_code: model.reward(state,grid_code)[0][0][0]\n",
    "    rewards = []\n",
    "\n",
    "    for index, row in temp_after_be_data.iterrows():\n",
    "        coords = (row.x, row.y)\n",
    "        state = row[1:15] \n",
    "        pe_code = globalPE(coords, len(state))\n",
    "        pe_code = np.expand_dims(np.expand_dims(np.expand_dims(pe_code, axis=0), axis=0), axis=0)\n",
    "        state = np.expand_dims(np.expand_dims(np.expand_dims(state, axis=0), axis=0), axis=0)\n",
    "        reward = float(rewardFunction(state, pe_code))\n",
    "        rewards.append(reward)\n",
    "    temp_after_be_data['reward'] = rewards\n",
    "    \n",
    "    # Save the updated DataFrame to a CSV file in the save_dir\n",
    "    csv_file_name = pickle_file.replace('.pickle', '.csv')\n",
    "    csv_file_path = os.path.join(save_dir, csv_file_name)\n",
    "    temp_after_be_data.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def process_file(pickle_file, model_dir, save_dir, after_be_data, globalPE, getComputeFunction):\n",
    "    temp_after_be_data = after_be_data.copy()\n",
    "    file_path = os.path.join(model_dir, pickle_file)\n",
    "    model.loadParams(file_path)\n",
    "    rewardFunction = getComputeFunction(model, 'reward')\n",
    "    \n",
    "    def calculate_reward(row):\n",
    "        coords = (row.x, row.y)\n",
    "        state = row[1:15]\n",
    "        pe_code = globalPE(coords, len(state))\n",
    "        pe_code = np.expand_dims(np.expand_dims(np.expand_dims(pe_code, axis=0), axis=0), axis=0)\n",
    "        state = np.expand_dims(np.expand_dims(np.expand_dims(state, axis=0), axis=0), axis=0)\n",
    "        return float(rewardFunction(state, pe_code))\n",
    "    \n",
    "    temp_after_be_data['reward'] = temp_after_be_data.apply(calculate_reward, axis=1)\n",
    "    \n",
    "    # Save the updated DataFrame to a CSV file in the save_dir\n",
    "    csv_file_name = pickle_file.replace('.pickle', '.csv')\n",
    "    csv_file_path = os.path.join(save_dir, csv_file_name)\n",
    "    temp_after_be_data.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Directories\n",
    "model_dir = './data_pe/after_migrt/model/'\n",
    "save_dir = './data_pe/after_migrt/all_grid/'\n",
    "\n",
    "# Make sure the save directory exists\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# List of pickle files\n",
    "pickle_files = [file for file in os.listdir(model_dir) if file.endswith('.pickle')]\n",
    "\n",
    "# Number of workers in the pool\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "# Processing files in parallel\n",
    "with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "    # Submit tasks\n",
    "    futures = [executor.submit(process_file, pickle_file, model_dir, save_dir, after_be_data, globalPE, getComputeFunction)\n",
    "               for pickle_file in pickle_files]\n",
    "    \n",
    "    # Progress bar for the futures\n",
    "    for _ in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
